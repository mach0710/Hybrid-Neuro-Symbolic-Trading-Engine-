import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.graph import StateGraph, END
from typing import TypedDict, Dict, Any

# --- 1. DEFINE LLM WITH SPECIFIC VERSION ---
# Using the specific version number '-001' often resolves the 404 error
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash-001", 
    temperature=0
)

# --- 2. DEFINE STATE & AGENTS ---
class AgentState(TypedDict):
    ticker: str
    market_data: Dict[str, Any]
    technical_analysis: str
    fundamental_analysis: str
    risk_analysis: str
    final_verdict: str

# Technical Agent (The one that was failing)
def technical_agent(state):
    print(f" Tech Agent: Analyzing {state['ticker']}...")
    prompt = f"Analyze technicals for {state['ticker']} with data: {state['market_data']}"
    try:
        response = llm.invoke([SystemMessage(content="You are a Technical Analyst."), HumanMessage(content=prompt)])
        return {"technical_analysis": response.content}
    except Exception as e:
        return {"technical_analysis": f"Error: {str(e)}"}

# Mock other agents for the example
def fundamental_agent(state): return {"fundamental_analysis": "Fundamentals look stable."}
def risk_agent(state): return {"risk_analysis": "Risk is moderate."}
def verdict_agent(state): return {"final_verdict": "BUY - Technical breakout likely."}

# --- 3. BUILD GRAPH ---
workflow = StateGraph(AgentState)
workflow.add_node("technical_agent", technical_agent)
workflow.add_node("fundamental_agent", fundamental_agent)
workflow.add_node("risk_agent", risk_agent)
workflow.add_node("verdict_agent", verdict_agent)

workflow.set_entry_point("technical_agent")
workflow.add_edge("technical_agent", "fundamental_agent")
workflow.add_edge("fundamental_agent", "risk_agent")
workflow.add_edge("risk_agent", "verdict_agent")
workflow.add_edge("verdict_agent", END)

app_graph = workflow.compile()
